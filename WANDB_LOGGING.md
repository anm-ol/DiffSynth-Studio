# Wandb Logging Integration

This document explains how to use the Weights & Biases (wandb) logging feature that has been integrated into the DiffSynth training scripts.

## Installation

First, make sure you have wandb installed:

```bash
pip install wandb
```

Or install all requirements including wandb:

```bash
pip install -r requirements.txt
```

## Setup

Before using wandb logging, you need to login to your wandb account:

```bash
wandb login
```

This will prompt you to enter your API key, which you can find at https://wandb.ai/authorize

## Usage

### Basic Usage

To enable wandb logging in your training, add the `--use_wandb` flag:

```bash
python examples/wanvideo/model_training/train.py \
    --dataset_base_path /path/to/dataset \
    --use_wandb \
    --wandb_project "my-diffsynth-project" \
    --wandb_run_name "experiment-1" \
    --learning_rate 1e-4 \
    --num_epochs 10
```

### Available Wandb Arguments

- `--use_wandb`: Enable wandb logging (default: False)
- `--wandb_project`: Wandb project name (default: "diffsynth-training")
- `--wandb_run_name`: Custom run name (default: auto-generated by wandb)
- `--wandb_entity`: Wandb entity/team name (default: None, uses your personal account)

### Validation and Checkpoint Arguments

- `--save_every_n_epochs`: Save checkpoint every N epochs (default: 1, save every epoch)
- `--validate_every_n_epochs`: Run validation every N epochs (default: None, no validation)
- `--validation_dataset_base_path`: Base path of validation dataset (default: None, uses prompt-based validation)
- `--validation_dataset_metadata_path`: Path to validation dataset metadata file
- `--validation_prompt`: Prompt for validation video generation (default: "a beautiful landscape")
- `--validation_negative_prompt`: Negative prompt for validation (default: "")
- `--validation_num_frames`: Number of frames for validation video (default: 49)
- `--validation_height`: Height for validation video (default: 480)
- `--validation_width`: Width for validation video (default: 832)
- `--validation_seed`: Seed for validation generation (default: 42)

### What Gets Logged

The integration automatically logs:

**Per Step:**
- `train/loss`: Training loss value for each step
- `train/step`: Step number

**Per Epoch:**
- `train/epoch`: Epoch number (only when checkpoint is saved)
- `train/checkpoint_saved`: Path to saved checkpoint (only when checkpoint is saved)

**Validation (if enabled):**
- `validation/epoch`: Epoch number when validation runs
- `validation/video`: Generated validation video (logged to wandb as video)
- `validation/prompt`: Prompt used for validation
- `validation/source`: "dataset" if using validation dataset, "prompt" if using prompt-based generation

**Training Configuration:**
- `learning_rate`: Learning rate
- `num_epochs`: Number of training epochs
- `gradient_accumulation_steps`: Gradient accumulation steps
- `lora_rank`: LoRA rank (if using LoRA)
- `num_frames`: Number of frames per video
- `dataset_base_path`: Dataset path
- `trainable_models`: Which models are being trained
- `lora_base_model`: Base model for LoRA
- `lora_target_modules`: Target modules for LoRA
- `save_every_n_epochs`: Checkpoint saving frequency
- `validate_every_n_epochs`: Validation frequency
- `validation_prompt`: Validation prompt

## Example Training Command

```bash
python examples/wanvideo/model_training/train.py \
    --dataset_base_path ./data/dataset_v1/train \
    --model_id_with_origin_paths "Wan-AI/Wan2.1-T2V-1.3B:diffusion_pytorch_model*.safetensors" \
    --trainable_models "dit" \
    --lora_base_model "dit" \
    --lora_rank 32 \
    --learning_rate 1e-4 \
    --num_epochs 50 \
    --gradient_accumulation_steps 4 \
    --output_path "./models/trained" \
    --use_wandb \
    --wandb_project "vace-training" \
    --wandb_run_name "lora-dit-r32-lr1e4" \
    --save_every_n_epochs 5 \
    --validate_every_n_epochs 10 \
    --validation_dataset_base_path "./data/dataset_v1/val" \
    --validation_dataset_metadata_path "./data/dataset_v1/val/metadata.csv" \
    --validation_prompt "a beautiful sunset over mountains" \
    --validation_negative_prompt "blurry, low quality" \
    --validation_num_frames 49
```

### Key Features:

1. **Storage Optimization**: `--save_every_n_epochs 5` saves checkpoints only every 5 epochs instead of every epoch
2. **Validation Monitoring**: `--validate_every_n_epochs 10` generates validation videos every 10 epochs
3. **Separate Validation Dataset**: `--validation_dataset_base_path` uses dedicated validation data for more accurate evaluation
4. **Wandb Video Logging**: Validation videos are automatically uploaded to wandb for easy monitoring
5. **Dual Validation Modes**: 
   - **Dataset-based**: Uses real validation data with vace_video and reference images
   - **Prompt-based**: Falls back to prompt-only generation if no validation dataset is provided

## Viewing Results

After starting training with wandb enabled:

1. Open your browser and go to https://wandb.ai
2. Navigate to your project
3. View real-time training metrics, including:
   - Loss curves
   - Training progress
   - System metrics (GPU/CPU usage, memory)
   - Hyperparameter tracking

## Notes

- If wandb is not installed and `--use_wandb` is specified, the training will continue without logging and display a warning
- Only the main process logs to wandb in distributed training scenarios
- All training configuration is automatically logged as part of the wandb config
- Checkpoints are saved locally and the paths are logged to wandb for reference

## Troubleshooting

1. **Import Error**: Make sure wandb is installed: `pip install wandb`
2. **Authentication Error**: Run `wandb login` and enter your API key
3. **Network Issues**: Wandb can work offline - logs will be synced when network is available
4. **Permission Issues**: Check that you have access to the specified project/entity
